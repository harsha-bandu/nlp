{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-fbebe5c48c0e>:4: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
      "  pd.set_option(\"display.max_colwidth\", -1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status information</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raja</td>\n",
       "      <td>hyderabad</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anirudh Reddy</td>\n",
       "      <td>pune</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sapna Dewani</td>\n",
       "      <td>bangalore</td>\n",
       "      <td>Converted</td>\n",
       "      <td>16|AuG|moHan:rnr</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>suresh</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akshay Shinde</td>\n",
       "      <td>hyderabad</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lead Name   Location        Status   \\\n",
       "0  Raja           hyderabad  Not Converted   \n",
       "1  Anirudh Reddy  pune       Not Converted   \n",
       "2  Sapna Dewani   bangalore  Converted       \n",
       "3  suresh         mumbai     Not Converted   \n",
       "4  Akshay Shinde  hyderabad  Not Converted   \n",
       "\n",
       "                                                                                                                                                            Status information  \\\n",
       "0  14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now                                         \n",
       "1  14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification   \n",
       "2  16|AuG|moHan:rnr                                                                                                                                                              \n",
       "3  14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server                                                                                        \n",
       "4  14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details                                                        \n",
       "\n",
       "   Unnamed: 4  \n",
       "0 NaN          \n",
       "1 NaN          \n",
       "2 NaN          \n",
       "3 NaN          \n",
       "4 NaN          "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('1000 leads.xlsx')\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not Converted    867\n",
      "Converted        131\n",
      "Name: Status, dtype: int64\n",
      "['Not Converted' 'Converted' nan]\n",
      "['hyderabad' 'pune' 'bangalore' 'mumbai' 'delhi' 'australia' 'nagpur'\n",
      " 'madurai' 'mysore' 'chennai' 'kerala' 'hubli' 'guntur' 'Bangalore'\n",
      " 'Hyderabad' 'jalandhar' 'tiruttani' 'USA' 'Faridabad' 'Online' 'gurgoan'\n",
      " 'kochi' 'noida' 'ahmedabad' 'khammam' 'Chennai' 'vishakapatnam' 'solapur'\n",
      " 'Mumbai' 'nasik' 'Thane' 'UAE' 'Aurangabad' 'rayagada' 'bilgi' 'gurgaon'\n",
      " 'Rajamundry' 'kadapa' 'aurangabad' 'kolkatta' 'vijayawada' 'Vijayawada'\n",
      " 'Pune' 'India' 'india' 'meerut' 'jaipur' 'coimbatore' 'gujarat'\n",
      " 'ghazibad' 'ongole' 'Nepal' 'Gurgaon' 'bihar' 'thane']\n",
      "(55,)\n",
      "['Hyderabad' 'Pune' 'Bangalore' 'Mumbai' 'Delhi' 'Australia' 'Nagpur'\n",
      " 'Madurai' 'Mysore' 'Chennai' 'Kerala' 'Hubli' 'Guntur' 'Jalandhar'\n",
      " 'Tiruttani' 'Usa' 'Faridabad' 'Online' 'Gurgoan' 'Kochi' 'Noida'\n",
      " 'Ahmedabad' 'Khammam' 'Vishakapatnam' 'Solapur' 'Nasik' 'Thane' 'Uae'\n",
      " 'Aurangabad' 'Rayagada' 'Bilgi' 'Gurgaon' 'Rajamundry' 'Kadapa'\n",
      " 'Kolkatta' 'Vijayawada' 'India' 'Meerut' 'Jaipur' 'Coimbatore' 'Gujarat'\n",
      " 'Ghazibad' 'Ongole' 'Nepal' 'Bihar']\n",
      "(45,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(832,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "\n",
    "#Remove last column\n",
    "\n",
    "data_r = data.drop('Unnamed: 4', axis = 1)\n",
    "data_r.head()\n",
    "\n",
    "#data_r['Status information'] = data_r['Status information']\n",
    "\n",
    "data_r.columns = data_r.columns.str.strip()\n",
    "data_r.columns = data_r.columns.str.replace(\" \",\"_\")\n",
    "\n",
    "data_r['Status'].value_counts()\n",
    "\n",
    "#Formatting the Status column\n",
    "\n",
    "data_r['Status'] = data_r['Status'].str.strip()\n",
    "data_new = data_r.replace({'Status': {'NOt Converted':'Not Converted', 'Conveted':'Converted'}})\n",
    "print(data_new['Status'].value_counts())\n",
    "print(data_new['Status'].unique())\n",
    "\n",
    "#Filling missing values\n",
    "\n",
    "data_new['Status'] = data_new['Status'].fillna(method = 'ffill')\n",
    "data_new['Location'] = data_r['Location'].fillna(method = 'ffill')\n",
    "data_new['Status_information'] = data_r['Status_information'].fillna(method = 'ffill')\n",
    "data_new.head()\n",
    "\n",
    "data_new['Status'].value_counts()\n",
    "\n",
    "#Formatting Location column -- Repetitive values with change in case of letters\n",
    "\n",
    "print(data_new['Location'].unique())\n",
    "print(data_new['Location'].unique().shape)\n",
    "\n",
    "data_new['Location'] = data_new['Location'].str.title()\n",
    "\n",
    "print(data_new['Location'].unique())\n",
    "print(data_new['Location'].unique().shape)\n",
    "\n",
    "#Formatting Lead Name column -- Repetitive values with change in case of letters\n",
    "\n",
    "data_new['Lead_Name'].unique().shape\n",
    "\n",
    "data_new['Lead_Name'] = data_new['Lead_Name'].str.title()\n",
    "data_new['Lead_Name'].unique().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lead_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Status</th>\n",
       "      <th>Status_information</th>\n",
       "      <th>Status_information_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Raja</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now</td>\n",
       "      <td>share me details, available in evng   postponed the plans for training currently   not interested now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anirudh Reddy</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification</td>\n",
       "      <td>cal me tmrw, shared details to email   share details to email, will check n revert   received your email, i'm looking for ASQ certification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sapna Dewani</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Converted</td>\n",
       "      <td>16|AuG|moHan:rnr</td>\n",
       "      <td>rnr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suresh</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server</td>\n",
       "      <td>i want only Server  cal busy  reg for server</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Akshay Shinde</td>\n",
       "      <td>Hyderabad</td>\n",
       "      <td>Not Converted</td>\n",
       "      <td>14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details</td>\n",
       "      <td>rnr   gave info, he said he will revert in  hr   planning for next month, share details</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lead_Name   Location         Status  \\\n",
       "0  Raja           Hyderabad  Not Converted   \n",
       "1  Anirudh Reddy  Pune       Not Converted   \n",
       "2  Sapna Dewani   Bangalore  Converted       \n",
       "3  Suresh         Mumbai     Not Converted   \n",
       "4  Akshay Shinde  Hyderabad  Not Converted   \n",
       "\n",
       "                                                                                                                                                            Status_information  \\\n",
       "0  14/8/prema: share me details, available in evng 18/8/prema: postponed the plans for training currently 9/11/prema: not interested now                                         \n",
       "1  14/8/prema: cal me tmrw, shared details to email 16/8/prema: share details to email, will check n revert 18/8/prema: received your email, i'm looking for ASQ certification   \n",
       "2  16|AuG|moHan:rnr                                                                                                                                                              \n",
       "3  14/8/17(Surendra):i want only Server 16|AuG|moHan:cal busy 17|AuG|moHan:reg for server                                                                                        \n",
       "4  14/8/prema:rnr 16/8/prema: gave info, he said he will revert in 1hr 30/8/prema: planning for next month, share details                                                        \n",
       "\n",
       "                                                                                                                  Status_information_processed  \n",
       "0  share me details, available in evng   postponed the plans for training currently   not interested now                                        \n",
       "1  cal me tmrw, shared details to email   share details to email, will check n revert   received your email, i'm looking for ASQ certification  \n",
       "2  rnr                                                                                                                                          \n",
       "3  i want only Server  cal busy  reg for server                                                                                                 \n",
       "4  rnr   gave info, he said he will revert in  hr   planning for next month, share details                                                      "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new['Status_information_processed'] = data_new.Status_information.str.replace('(\\w+)(\\||/|-)(\\w+)(\\||/|-)(.*?\\w+.*?):',\" \")\n",
    "data_new['Status_information_processed'] = data_new.Status_information_processed.str.replace('(\\d+)',\" \")\n",
    "data_new['Status_information_processed'] = data_new['Status_information_processed'].str.strip()\n",
    "\n",
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\harsh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Removing punc, Tokenization, stop words removal and Stemming\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "def clean_text(sentence):\n",
    "    text = ''.join([word.lower() for word in sentence if word not in string.punctuation])\n",
    "    word = re.split('\\W+',text)\n",
    "    token = [ps.stem(term) for term in word if term not in stop_words]\n",
    "    return token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_words = CountVectorizer(analyzer = clean_text).fit(data_new['Status_information_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1103\n"
     ]
    }
   ],
   "source": [
    "print(len(bag_words.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=<function clean_text at 0x0000020FD2BBC670>)\n"
     ]
    }
   ],
   "source": [
    "print(bag_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_bagwords = bag_words.transform(data_new['Status_information_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 82)\t1\n",
      "  (0, 222)\t1\n",
      "  (0, 253)\t1\n",
      "  (0, 337)\t1\n",
      "  (0, 482)\t1\n",
      "  (0, 717)\t1\n",
      "  (0, 740)\t1\n",
      "  (0, 889)\t1\n",
      "  (0, 997)\t1\n",
      "  (1, 57)\t1\n",
      "  (1, 132)\t1\n",
      "  (1, 147)\t1\n",
      "  (1, 152)\t1\n",
      "  (1, 253)\t2\n",
      "  (1, 312)\t3\n",
      "  (1, 463)\t1\n",
      "  (1, 558)\t1\n",
      "  (1, 627)\t1\n",
      "  (1, 795)\t1\n",
      "  (1, 826)\t1\n",
      "  (1, 889)\t2\n",
      "  (1, 982)\t1\n",
      "  (2, 829)\t1\n",
      "  (3, 126)\t1\n",
      "  (3, 132)\t1\n",
      "  :\t:\n",
      "  (998, 494)\t1\n",
      "  (998, 705)\t1\n",
      "  (998, 802)\t1\n",
      "  (998, 996)\t1\n",
      "  (999, 253)\t1\n",
      "  (999, 290)\t1\n",
      "  (999, 397)\t1\n",
      "  (999, 721)\t1\n",
      "  (999, 889)\t1\n",
      "  (1000, 89)\t2\n",
      "  (1000, 132)\t2\n",
      "  (1000, 134)\t1\n",
      "  (1000, 146)\t1\n",
      "  (1000, 253)\t2\n",
      "  (1000, 386)\t1\n",
      "  (1000, 463)\t1\n",
      "  (1000, 485)\t1\n",
      "  (1000, 502)\t1\n",
      "  (1000, 534)\t2\n",
      "  (1000, 584)\t2\n",
      "  (1000, 633)\t2\n",
      "  (1000, 726)\t1\n",
      "  (1000, 829)\t2\n",
      "  (1000, 889)\t2\n",
      "  (1000, 1012)\t2\n"
     ]
    }
   ],
   "source": [
    "print(message_bagwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer().fit(message_bagwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_tfidf = tfidf_transformer.transform(message_bagwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1001, 1103)\n",
      "  (0, 997)\t0.35311068357045317\n",
      "  (0, 889)\t0.1481997835433517\n",
      "  (0, 740)\t0.43342483572326873\n",
      "  (0, 717)\t0.3741551594515137\n",
      "  (0, 482)\t0.2655807184882078\n",
      "  (0, 337)\t0.3364175748910053\n",
      "  (0, 253)\t0.16144426109860333\n",
      "  (0, 222)\t0.4218203951251419\n",
      "  (0, 82)\t0.37120600726108743\n",
      "  (1, 982)\t0.16901141649659332\n",
      "  (1, 889)\t0.17449012745547843\n",
      "  (1, 826)\t0.18294699144287782\n",
      "  (1, 795)\t0.3251585520541809\n",
      "  (1, 627)\t0.20032241432293527\n",
      "  (1, 558)\t0.19917201602879078\n",
      "  (1, 463)\t0.21685337145009556\n",
      "  (1, 312)\t0.6195931473135724\n",
      "  (1, 253)\t0.19008414872488905\n",
      "  (1, 152)\t0.14068311771967631\n",
      "  (1, 147)\t0.3007721356891113\n",
      "  (1, 132)\t0.16122268457847524\n",
      "  (1, 57)\t0.34451513967979164\n",
      "  (2, 829)\t1.0\n",
      "  (3, 1038)\t0.222840366269183\n",
      "  (3, 878)\t0.8300926013920176\n",
      "  :\t:\n",
      "  (998, 345)\t0.45453042888439776\n",
      "  (998, 337)\t0.2612923060171013\n",
      "  (998, 102)\t0.27425768353300595\n",
      "  (998, 28)\t0.38533547661023687\n",
      "  (999, 889)\t0.19849734815176545\n",
      "  (999, 721)\t0.4409334098869116\n",
      "  (999, 397)\t0.6843077279253498\n",
      "  (999, 290)\t0.5011397801853142\n",
      "  (999, 253)\t0.2162368725256589\n",
      "  (1000, 1012)\t0.2874818415006604\n",
      "  (1000, 889)\t0.1565561079712624\n",
      "  (1000, 829)\t0.13909932223037966\n",
      "  (1000, 726)\t0.14701933147859916\n",
      "  (1000, 633)\t0.2580161881786729\n",
      "  (1000, 584)\t0.4127958546639735\n",
      "  (1000, 534)\t0.33587350331017984\n",
      "  (1000, 502)\t0.27941672538804013\n",
      "  (1000, 485)\t0.27941672538804013\n",
      "  (1000, 463)\t0.1945652761548689\n",
      "  (1000, 386)\t0.15999544901629467\n",
      "  (1000, 253)\t0.17054738251017823\n",
      "  (1000, 146)\t0.29173889735487973\n",
      "  (1000, 134)\t0.09931879616264268\n",
      "  (1000, 132)\t0.2893045742169534\n",
      "  (1000, 89)\t0.2733794657354284\n"
     ]
    }
   ],
   "source": [
    "print(message_tfidf.shape)\n",
    "print(message_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(message_tfidf,data_new['Status'] , test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect = MultinomialNB().fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn import svm\n",
    "#spam_detect = svm.SVC(kernel='linear', C=1,gamma= 10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = spam_detect.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8805970149253731"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "expected = y_test\n",
    "\n",
    "accuracy_score(expected,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Converted       0.00      0.00      0.00        24\n",
      "Not Converted       0.88      1.00      0.94       177\n",
      "\n",
      "     accuracy                           0.88       201\n",
      "    macro avg       0.44      0.50      0.47       201\n",
      " weighted avg       0.78      0.88      0.82       201\n",
      "\n",
      "[[  0  24]\n",
      " [  0 177]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harsh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving\n",
    "import pickle\n",
    "\n",
    "pickle.dump(spam_detect, open(\"spam_model.pkl\", \"wb\" ))\n",
    "\n",
    "my_scaler = pickle.load(open(\"spam_model.pkl\", \"rb\" ))\n",
    "\n",
    "predictions = my_scaler.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
